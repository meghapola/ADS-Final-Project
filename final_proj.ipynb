{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d30b10-773a-40ff-b6ec-e255c987cd35",
   "metadata": {},
   "source": [
    "## **Applied Data Science Final Project**\n",
    "\n",
    "##### Megha Polavarapu (mp4392), Xiaoying Wang (xw2993), Iris June Chang (ijc2119), Mengyan Li (ml4779)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cdeee0-bea1-4cc4-b69b-c9a181e066d6",
   "metadata": {},
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a4f6a7-a861-4547-bc62-39146a5988a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import dateutil\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f8e0f77-d270-4347-933a-3b56a984ca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from fastparquet) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from fastparquet) (1.26.4)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from fastparquet) (2024.6.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from fastparquet) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Downloading fastparquet-2024.11.0-cp312-cp312-macosx_11_0_arm64.whl (685 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m685.4/685.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cramjam-2.10.0-cp312-cp312-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cramjam, fastparquet\n",
      "Successfully installed cramjam-2.10.0 fastparquet-2024.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5bfa6a-4f75-4621-b61d-ba84acb49437",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057dd557-c7e5-41d6-a90c-30a4d5da0813",
   "metadata": {},
   "source": [
    "#### **Ballot Data for 2020 Election**\n",
    "Data Source Link: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/PQQ3KV \n",
    "\n",
    "Citation: \n",
    "Kuriwaki, Shiro; Reece, Mason; Baltz, Samuel; Conevska, Aleksandra; Loffredo, Joseph R.; Samarth, Taran; Mutlu, Can; Acevedo Jetter, Kevin E.; Garai, Zachary Djanogly; Murray, Kate; Hirano, Shigeo; Lewis, Jeffrey B.; Snyder, James M. Jr.; Stewart, Charles H. III, 2024, \"Cast Vote Records: A Database of Ballots from the 2020 U.S. Election\", https://doi.org/10.7910/DVN/PQQ3KV, Harvard Dataverse, V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a7a412e1-9452-4458-985a-9b41a6745fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_NAME = 'data/raw/election_data/release/'\n",
    "outer_filenames = next(os.walk(PATH_NAME), (None, None, []))[1]\n",
    "states = [state[6:].replace('%20',' ') for state in outer_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "798181f5-bb1f-4cbe-9669-afabbd0dc5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for  MICHIGAN\n",
      "Loading data for  DELAWARE\n",
      "Loading data for  WISCONSIN\n",
      "Loading data for  COLORADO\n",
      "Loading data for  FLORIDA\n",
      "Loading data for  TEXAS\n",
      "Loading data for  NEW JERSEY\n",
      "Loading data for  ARIZONA\n",
      "Loading data for  ILLINOIS\n",
      "Loading data for  WEST VIRGINIA\n",
      "Loading data for  TENNESSEE\n",
      "Loading data for  RHODE ISLAND\n",
      "Loading data for  OREGON\n",
      "Loading data for  MARYLAND\n",
      "Loading data for  GEORGIA\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m     14\u001b[0m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounty\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m c[\u001b[38;5;241m12\u001b[39m:]\n\u001b[0;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df,d], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    686\u001b[0m )\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/concat.py:189\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    187\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m values\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     values \u001b[38;5;241m=\u001b[39m _concatenate_join_units(join_units, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    190\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/concat.py:467\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, copy)\u001b[0m\n\u001b[1;32m    463\u001b[0m has_none_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(unit\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    464\u001b[0m upcasted_na \u001b[38;5;241m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[1;32m    466\u001b[0m to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 467\u001b[0m     ju\u001b[38;5;241m.\u001b[39mget_reindexed_values(empty_dtype\u001b[38;5;241m=\u001b[39mempty_dtype, upcasted_na\u001b[38;5;241m=\u001b[39mupcasted_na)\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[1;32m    469\u001b[0m ]\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat):\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special case not needed if all EAs used HybridBlocks\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"__getitem__\" of \"ExtensionArray\" matches\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# argument type \"Tuple[int, slice]\"\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    477\u001b[0m         t\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m t[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat\n\u001b[1;32m    481\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/concat.py:440\u001b[0m, in \u001b[0;36mJoinUnit.get_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m upcasted_na\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_valid_na_for(empty_dtype):\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;66;03m# note: always holds when self.block.dtype.kind == \"V\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m         blk_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m blk_dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    445\u001b[0m             \u001b[38;5;66;03m# we want to avoid filling with np.nan if we are\u001b[39;00m\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# using None; we already know that we are all\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# nulls\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/concat.py:371\u001b[0m, in \u001b[0;36mJoinUnit._is_valid_na_for\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    370\u001b[0m     values \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_valid_na_for_dtype(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m values\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    373\u001b[0m na_value \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m NaT \u001b[38;5;129;01mand\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# e.g. we are dt64 and other is td64\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# fill_values match but we should not cast blk.values to dtype\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# TODO: this will need updating if we ever have non-nano dt64/td64\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/concat.py:371\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    370\u001b[0m     values \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_valid_na_for_dtype(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m values\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    373\u001b[0m na_value \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m NaT \u001b[38;5;129;01mand\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# e.g. we are dt64 and other is td64\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# fill_values match but we should not cast blk.values to dtype\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# TODO: this will need updating if we ever have non-nano dt64/td64\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/missing.py:741\u001b[0m, in \u001b[0;36mis_valid_na_for_dtype\u001b[0;34m(obj, dtype)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_valid_na_for_dtype\u001b[39m(obj, dtype: DtypeObj) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    729\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03m    isna check that excludes incompatible dtypes\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_scalar(obj) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isna(obj):\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/missing.py:178\u001b[0m, in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m NDFrame:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _isna(obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/missing.py:184\u001b[0m, in \u001b[0;36m_isna\u001b[0;34m(obj, inf_as_na)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _isna(obj)\n\u001b[1;32m    181\u001b[0m isnull \u001b[38;5;241m=\u001b[39m isna\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_isna\u001b[39m(obj, inf_as_na: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Detect missing values, treating None, NaN or NA as null. Infinite\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    values will also be treated as null if inf_as_na is True.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m    boolean ndarray or boolean\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_scalar(obj):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state_counties = {} \n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i, file in enumerate(outer_filenames): \n",
    "    counties = next(os.walk(PATH_NAME+file), (None, None, []))[1]\n",
    "    state = states[i]\n",
    "    state_counties[state] = [county[12:].replace('%20',' ') for county in counties]\n",
    "    print('Loading data for ', state)\n",
    "    \n",
    "    for c in counties:\n",
    "        file_path = PATH_NAME + file + '/' + c + '/part-0.parquet'\n",
    "        d = pd.read_parquet(file_path, engine='fastparquet')\n",
    "        d['state'] = state\n",
    "        d['county'] = c[12:]\n",
    "        df = pd.concat([df,d], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d19f0d26-db7d-4a16-b1e3-3597837ac7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.state != 'GEORGIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a5b053c8-3a2c-4215-bd3e-7b7618257ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for  GEORGIA\n",
      "Loading data for  OHIO\n",
      "Loading data for  UTAH\n",
      "Loading data for  IOWA\n",
      "Loading data for  CALIFORNIA\n",
      "Loading data for  NEVADA\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "for i, file in enumerate(outer_filenames[14:]): \n",
    "    counties = next(os.walk(PATH_NAME+file), (None, None, []))[1]\n",
    "    state = states[14+i]\n",
    "    state_counties[state] = [county[12:].replace('%20',' ') for county in counties]\n",
    "    print('Loading data for ', state)\n",
    "\n",
    "    for c in counties:\n",
    "        file_path = PATH_NAME + file + '/' + c + '/part-0.parquet'\n",
    "        d = pd.read_parquet(file_path, engine='fastparquet')\n",
    "        d['state'] = state\n",
    "        d['county'] = c[12:]\n",
    "        df2 = pd.concat([df2,d], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4726132f-1c2d-4744-8f68-e624856323b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([df,df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c77cdd2-39cc-42f2-b3a2-93c140b183d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(\"data/2020_ballot.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56363c9-123b-4eb8-b277-dcd551425aa9",
   "metadata": {},
   "source": [
    "#### **Presidential Election Data 1976-2020**\n",
    "Data source link: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/42MVDX\n",
    "\n",
    "Citation:\n",
    "MIT Election Data and Science Lab, 2017, \"U.S. President 1976–2020\", https://doi.org/10.7910/DVN/42MVDX, Harvard Dataverse, V8, UNF:6:F0opd1IRbeYI9QyVfzglUw== [fileUNF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a343ce6d-78b0-4696-8ab7-965fcccadea6",
   "metadata": {},
   "source": [
    "#### **Presidential Election Data 2020 by Precinct**\n",
    "Data set link: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/NT66Z3\n",
    "Citation: MIT Election Data and Science Lab, 2022, \"Precinct-Level Returns 2020 by Individual State\", https://doi.org/10.7910/DVN/NT66Z3, Harvard Dataverse, V6, UNF:6:aViWPnsxmDD+s1GuFrrdpA== [fileUNF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "608b691b-e3c1-4c5d-8f40-ad1dee3c05af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-la-precinct-general.csv', '2020-tx-precinct-general.csv', '2020-nd-precinct-general.csv', '2020-ky-precinct-general.csv', '2020-mi-precinct-general.csv', '2020-ks-precinct-general.csv', '2020-wa-precinct-general.csv', '2020-or-precinct-general.csv', '2020-ms-precinct-general.csv', '2020-de-precinct-general.csv', '2020-ri-precinct-general.csv', '2020-oh-precinct-general.csv', '2020-ar-precinct-general.csv', '2020-al-precinct-general.csv', '2020-ut-precinct-general.csv', '2020-nj-precinct-general.csv', '2020-sd-precinct-general.csv', '2020-il-precinct-general.csv', '2020-ne-precinct-general.csv', '2020-nc-precinct-general-sorted.csv', '2020-ct-precinct-general.csv', '2020-nc-precinct-general.csv', '2020-mn-precinct-general.csv', '2020-fl-precinct-general.csv', '2020-wi-precinct-general.csv', '2020-ma-precinct-general.csv', '2020-tn-precinct-general.csv', '2020-md-precinct-general.csv', '2020-va-precinct-general.csv', '2020-ok-precinct-general.csv', '2020-ga-precinct-general.csv', '2020-co-precinct-general.csv', '2020-dc-precinct-general.csv', '2020-ia-precinct-general.csv', '2020-nh-precinct-general.csv', '2020-ak-precinct-general.csv', '2020-sc-precinct-general.csv', '2020-me-precinct-general.csv', '2020-nm-precinct-general.csv', '2020-id-precinct-general.csv', '2020-vt-precinct-general.csv', '2020-in-precinct-general.csv', '2020-pa-precinct-general.csv', '2020-mo-precinct-general.csv', '2020-az-precinct-general.csv', '2020-ny-precinct-general.csv', '2020-wv-precinct-general.csv', '2020-hi-precinct-general.csv', '2020-mt-precinct-general.csv', '2020-ca-precinct-general.csv', '2020-nv-precinct-general.csv', '2020-wy-precinct-general.csv']\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "PATH_NAME = 'data/raw/precinct_election_data/'\n",
    "\n",
    "filenames = next(os.walk(PATH_NAME), (None, None, []))[2]\n",
    "filenames.remove('README.md')\n",
    "filenames.remove('2020-precincts-codebook.md')\n",
    "filenames.remove('.Rhistory')\n",
    "print(filenames)\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a609508a-6ef5-47e8-a281-f504b7fff65d",
   "metadata": {},
   "source": [
    "Based on there being 52 file names, we can tell there is a duplicate (North Carolina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "16f14d8e-a2f8-44b3-93a4-64988099ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/2650330106.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nc = pd.read_csv(file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/2650330106.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nc_sorted = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696804\n",
      "1529852\n"
     ]
    }
   ],
   "source": [
    "file = 'data/raw/precinct_election_data/2020-nc-precinct-general.csv'\n",
    "nc = pd.read_csv(file)\n",
    "file = 'data/rawprecinct_election_data/2020-nc-precinct-general-sorted.csv'\n",
    "nc_sorted = pd.read_csv(file)\n",
    "\n",
    "print(nc.shape[0])\n",
    "print(nc_sorted.shape[0])\n",
    "\n",
    "filenames.remove('2020-nc-precinct-general-sorted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369a5361-b12f-49fa-b96f-338363bf72eb",
   "metadata": {},
   "source": [
    "We choose to keep the sorted data because it has more data. Based on the readMe for this dataset, contains additional information about the ballots used which could be used and therefore, this dataset will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0e8502fe-bc7f-4d5b-908f-e33f4138c321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-la-precinct-general.csv\n",
      "Loading file  2020-tx-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (2,3,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-nd-precinct-general.csv\n",
      "Loading file  2020-ky-precinct-general.csv\n",
      "Loading file  2020-mi-precinct-general.csv\n",
      "Loading file  2020-ks-precinct-general.csv\n",
      "Loading file  2020-wa-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-or-precinct-general.csv\n",
      "Loading file  2020-ms-precinct-general.csv\n",
      "Loading file  2020-de-precinct-general.csv\n",
      "Loading file  2020-ri-precinct-general.csv\n",
      "Loading file  2020-oh-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-ar-precinct-general.csv\n",
      "Loading file  2020-al-precinct-general.csv\n",
      "Loading file  2020-ut-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-nj-precinct-general.csv\n",
      "Loading file  2020-sd-precinct-general.csv\n",
      "Loading file  2020-il-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (0,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-ne-precinct-general.csv\n",
      "Loading file  2020-ct-precinct-general.csv\n",
      "Loading file  2020-nc-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-mn-precinct-general.csv\n",
      "Loading file  2020-fl-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (2,3,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-wi-precinct-general.csv\n",
      "Loading file  2020-ma-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-tn-precinct-general.csv\n",
      "Loading file  2020-md-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-va-precinct-general.csv\n",
      "Loading file  2020-ok-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-ga-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-co-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-dc-precinct-general.csv\n",
      "Loading file  2020-ia-precinct-general.csv\n",
      "Loading file  2020-nh-precinct-general.csv\n",
      "Loading file  2020-ak-precinct-general.csv\n",
      "Loading file  2020-sc-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-me-precinct-general.csv\n",
      "Loading file  2020-nm-precinct-general.csv\n",
      "Loading file  2020-id-precinct-general.csv\n",
      "Loading file  2020-vt-precinct-general.csv\n",
      "Loading file  2020-in-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-pa-precinct-general.csv\n",
      "Loading file  2020-mo-precinct-general.csv\n",
      "Loading file  2020-az-precinct-general.csv\n",
      "Loading file  2020-ny-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-wv-precinct-general.csv\n",
      "Loading file  2020-hi-precinct-general.csv\n",
      "Loading file  2020-mt-precinct-general.csv\n",
      "Loading file  2020-ca-precinct-general.csv\n",
      "Loading file  2020-nv-precinct-general.csv\n",
      "Loading file  2020-wy-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    }
   ],
   "source": [
    "# file = 'data/raw/precinct_election_data/2020-wv-precinct-general.csv'\n",
    "combined = pd.DataFrame()\n",
    "for file in filenames:\n",
    "    print('Loading file ', file)\n",
    "    d = pd.read_csv(PATH_NAME + file)\n",
    "            \n",
    "    # standardizing formatting in precinct column \n",
    "    d['precinct'] = d['precinct'].replace('PRECINCT ', '')\n",
    "    d['votes'] = d['votes'].astype(int)\n",
    "    \n",
    "    # only keeping presidential election data \n",
    "    df = d.groupby(['candidate','office', 'party_detailed',\t'party_simplified',\t'state','state_po'], as_index=False)['votes'].sum()\n",
    "    \n",
    "    # re adding relevant data \n",
    "    # df = df.drop(columns = ['precinct', 'mode', \n",
    "    #        'county_name', 'county_fips', 'jurisdiction_name',\n",
    "    #        'jurisdiction_fips', 'district', 'magnitude', 'dataverse',\n",
    "    #        'year', 'stage', 'special', 'writein', 'state_fips', 'state_cen', 'state_ic', 'date', 'readme_check'])\n",
    "    # df = df.merge(d, left_on='candidate', right_on='candidate', how='left')\n",
    "    # df = df.drop_duplicates().reset_index()\n",
    "    # df= df.drop(columns = ['index'])\n",
    "    \n",
    "    combined = pd.concat([combined,df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f34e947d-3a17-4edf-9258-91e96072afb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate           object\n",
       "office              object\n",
       "party_detailed      object\n",
       "party_simplified    object\n",
       "state               object\n",
       "state_po            object\n",
       "votes                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "6223214e-1d86-4704-939a-957f3266256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['LOUISIANA', 'TEXAS', 'NORTH DAKOTA', 'KENTUCKY', 'MICHIGAN',\n",
      "       'KANSAS', 'WASHINGTON', 'OREGON', 'MISSISSIPPI', 'DELAWARE',\n",
      "       'RHODE ISLAND', 'OHIO', 'ARKANSAS', 'ALABAMA', 'UTAH',\n",
      "       'NEW JERSEY', 'SOUTH DAKOTA', 'ILLINOIS', 'NEBRASKA',\n",
      "       'CONNECTICUT', 'NORTH CAROLINA', 'MINNESOTA', 'FLORIDA',\n",
      "       'WISCONSIN', 'MASSACHUSETTS', 'TENNESSEE', 'MARYLAND', 'VIRGINIA',\n",
      "       'OKLAHOMA', 'GEORGIA', 'COLORADO', 'DISTRICT OF COLUMBIA', 'IOWA',\n",
      "       'NEW HAMPSHIRE', 'ALASKA', 'SOUTH CAROLINA', 'MAINE', 'NEW MEXICO',\n",
      "       'IDAHO', 'VERMONT', 'INDIANA', 'PENNSYLVANIA', 'MISSOURI',\n",
      "       'ARIZONA', 'NEW YORK', 'WEST VIRGINIA', 'HAWAII', 'MONTANA',\n",
      "       'CALIFORNIA', 'NEVADA', 'WYOMING'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "combined.head()\n",
    "print([combined[col_name].unique() for col_name in combined.columns if col_name == 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "ae867b21-f341-4f59-b917-33d05aca0d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('data/2020_election_vote_counts.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "d6ef8561-7c36-4626-805e-2779614a7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting who won each state \n",
    "top_candidates = combined.loc[combined.groupby(['office', 'state'])['votes'].idxmax()].reset_index(drop=True)\n",
    "top_candidates = top_candidates.sort_values('state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "96d8b09c-b0bc-4dfd-bd5d-1eb505606b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>office</th>\n",
       "      <th>party_detailed</th>\n",
       "      <th>party_simplified</th>\n",
       "      <th>state</th>\n",
       "      <th>state_po</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22835</th>\n",
       "      <td>MARY WINDOM</td>\n",
       "      <td>COURT OF CRIMINAL APPEALS JUDGE</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>1541862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22537</th>\n",
       "      <td>JOELETTA MARTIN BARRENTINE</td>\n",
       "      <td>CIRCUIT COURT JUDGE</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>26536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19299</th>\n",
       "      <td>TONYA SMITH CHESTNUT</td>\n",
       "      <td>STATE BOARD OF EDUCATION</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>161192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10242</th>\n",
       "      <td>TERRI A SEWELL</td>\n",
       "      <td>US HOUSE</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>225742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22697</th>\n",
       "      <td>DONALD J TRUMP</td>\n",
       "      <td>US PRESIDENT</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>1441170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>DONALD J TRUMP</td>\n",
       "      <td>US PRESIDENT</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>WY</td>\n",
       "      <td>193559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>BILL HENDERSON</td>\n",
       "      <td>STATE HOUSE</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>WY</td>\n",
       "      <td>2497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18228</th>\n",
       "      <td>LEVI J SHINKLE</td>\n",
       "      <td>STATE HOUSE</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>WY</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15575</th>\n",
       "      <td>OCEAN ANDREW</td>\n",
       "      <td>STATE HOUSE</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>WY</td>\n",
       "      <td>3409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>PETER H FROELICHER - NO</td>\n",
       "      <td>DISTRICT COURT JUDGE</td>\n",
       "      <td>NONPARTISAN</td>\n",
       "      <td>NONPARTISAN</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>WY</td>\n",
       "      <td>9222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24461 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        candidate                           office  \\\n",
       "22835                 MARY WINDOM  COURT OF CRIMINAL APPEALS JUDGE   \n",
       "22537  JOELETTA MARTIN BARRENTINE              CIRCUIT COURT JUDGE   \n",
       "19299        TONYA SMITH CHESTNUT         STATE BOARD OF EDUCATION   \n",
       "10242              TERRI A SEWELL                         US HOUSE   \n",
       "22697              DONALD J TRUMP                     US PRESIDENT   \n",
       "...                           ...                              ...   \n",
       "8275               DONALD J TRUMP                     US PRESIDENT   \n",
       "7836               BILL HENDERSON                      STATE HOUSE   \n",
       "18228              LEVI J SHINKLE                      STATE HOUSE   \n",
       "15575                OCEAN ANDREW                      STATE HOUSE   \n",
       "3705      PETER H FROELICHER - NO             DISTRICT COURT JUDGE   \n",
       "\n",
       "      party_detailed party_simplified    state state_po    votes  \n",
       "22835     REPUBLICAN       REPUBLICAN  ALABAMA       AL  1541862  \n",
       "22537     REPUBLICAN       REPUBLICAN  ALABAMA       AL    26536  \n",
       "19299       DEMOCRAT         DEMOCRAT  ALABAMA       AL   161192  \n",
       "10242       DEMOCRAT         DEMOCRAT  ALABAMA       AL   225742  \n",
       "22697     REPUBLICAN       REPUBLICAN  ALABAMA       AL  1441170  \n",
       "...              ...              ...      ...      ...      ...  \n",
       "8275      REPUBLICAN       REPUBLICAN  WYOMING       WY   193559  \n",
       "7836      REPUBLICAN       REPUBLICAN  WYOMING       WY     2497  \n",
       "18228       DEMOCRAT         DEMOCRAT  WYOMING       WY      816  \n",
       "15575     REPUBLICAN       REPUBLICAN  WYOMING       WY     3409  \n",
       "3705     NONPARTISAN      NONPARTISAN  WYOMING       WY     9222  \n",
       "\n",
       "[24461 rows x 7 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ac0269c0-c433-408d-b076-7a05d90cf2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_candidates.to_csv('data/2020_election_vote_results.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3586a4-d30d-43e5-b30e-60c5be94d25c",
   "metadata": {},
   "source": [
    "#### **NYT Web Scraping**\n",
    "##### References:    \n",
    "- https://github.com/susannapaoli/web-scraper-nyt/tree/main    \n",
    "- https://developer.nytimes.com/get-started    \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d228edd9-1ada-40ef-a8ce-5f9c7793689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'bgsBWGVUUDgyvMaTcXZZy4yd9Ogsehqh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "7d304711-de85-4b58-88d4-c70bdd1aaf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response):\n",
    "    data = {'headline': [],  \n",
    "        'date': [], \n",
    "        'web_url': [],\n",
    "        'doc_type': [],\n",
    "        'lead_paragraph': [],\n",
    "        'material_type': [],\n",
    "        'author': [],\n",
    "        'section': [],\n",
    "        'subsection': [],\n",
    "        'keywords': []}\n",
    "\n",
    "    articles = response['response']['docs'] \n",
    "    for article in articles: \n",
    "        date = dateutil.parser.parse(article['pub_date']).date()\n",
    "        # if date != datetime.date(2020, 1, 1):\n",
    "        #     continue\n",
    "        if type(article['headline']) == dict and 'main' in article['headline'].keys():\n",
    "            data['date'].append(date)\n",
    "            data['headline'].append(article['headline']['main']) \n",
    "            if 'section_name' in article:\n",
    "                data['section'].append(article['section_name'])\n",
    "            else:\n",
    "                data['section'].append(None)\n",
    "            if 'lead_paragraph' in article:\n",
    "                data['lead_paragraph'].append(article['lead_paragraph'])\n",
    "            else:\n",
    "                data['lead_paragraph'].append(None)\n",
    "            if 'web_url' in article:\n",
    "                data['web_url'].append(article['web_url'])\n",
    "            else:\n",
    "                data['web_url'].append(None)\n",
    "            if 'subsection_name' in article:\n",
    "                data['subsection'].append(article['subsection_name'])\n",
    "            else:\n",
    "                data['subsection'].append(None)\n",
    "            if 'byline' in article:\n",
    "                data['author'].append(article['byline']['original'])\n",
    "            else:\n",
    "                data['author'].append(None)\n",
    "            data['doc_type'].append(article['document_type'])\n",
    "            if 'type_of_material' in article: \n",
    "                data['material_type'].append(article['type_of_material'])\n",
    "            else:\n",
    "                data['material_type'].append(None)\n",
    "            keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
    "            data['keywords'].append(keywords)\n",
    "    return pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "316f2e98-6bf6-4375-82a5-277735964e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ['2020', '1']\n",
      "Working on ['2020', '2']\n",
      "Working on ['2020', '3']\n",
      "Working on ['2020', '4']\n",
      "Working on ['2020', '5']\n"
     ]
    }
   ],
   "source": [
    "# Get data from January 2020 to May 2020 \n",
    "for i in range(1,6): \n",
    "    date = ['2020', str(i)]\n",
    "    print('Working on', date)\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
    "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + API_KEY\n",
    "    response = requests.get(url, verify=False).json()\n",
    "    time.sleep(6) \n",
    "    \n",
    "    df = parse_response(response)\n",
    "    csv_path = 'data/raw/nyt_headlines/' + date[0] + '-' + date[1] + '.csv'\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0173ab5b-66ad-4374-9481-2a5af595fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ['2020', '6']\n",
      "Working on ['2020', '7']\n",
      "Working on ['2020', '8']\n",
      "Working on ['2020', '9']\n",
      "Working on ['2020', '10']\n",
      "Working on ['2020', '11']\n"
     ]
    }
   ],
   "source": [
    "# Get data from June 2020 to November 2020 \n",
    "for i in range(6,12): \n",
    "    date = ['2020', str(i)]\n",
    "    print('Working on', date)\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
    "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + API_KEY\n",
    "    response = requests.get(url, verify=False).json()\n",
    "    time.sleep(6) \n",
    "    \n",
    "    df = parse_response(response)\n",
    "    csv_path = 'data/raw/nyt_headlines/' + date[0] + '-' + date[1] + '.csv'\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "db495b64-b733-4a28-b699-d0f9343c024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['data/raw/nyt_headlines/2020-' + str(i) + '.csv' for i in range(1,12)]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for f in files:\n",
    "    d = pd.read_csv(f)\n",
    "    df = pd.concat([df,d], axis=0)\n",
    "\n",
    "#export to csv\n",
    "df.to_csv(\"data/nyt_data.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "aaa52386-446c-42c7-96ed-105403112fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = pd.read_csv('data/nyt_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "ae41eab4-9471-432d-be2f-693a0fe99e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>web_url</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>material_type</th>\n",
       "      <th>author</th>\n",
       "      <th>section</th>\n",
       "      <th>subsection</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51125</td>\n",
       "      <td>51128</td>\n",
       "      <td>51128</td>\n",
       "      <td>51128</td>\n",
       "      <td>50086</td>\n",
       "      <td>49878</td>\n",
       "      <td>45225</td>\n",
       "      <td>51127</td>\n",
       "      <td>21826</td>\n",
       "      <td>51128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49839</td>\n",
       "      <td>334</td>\n",
       "      <td>51127</td>\n",
       "      <td>3</td>\n",
       "      <td>43656</td>\n",
       "      <td>19</td>\n",
       "      <td>10431</td>\n",
       "      <td>51</td>\n",
       "      <td>83</td>\n",
       "      <td>32827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Coronavirus Briefing: What Happened Today</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>https://www.nytimes.com/2020/10/06/world/cuomo...</td>\n",
       "      <td>article</td>\n",
       "      <td>To the Editor:</td>\n",
       "      <td>News</td>\n",
       "      <td>By The New York Times</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>182</td>\n",
       "      <td>901</td>\n",
       "      <td>2</td>\n",
       "      <td>46933</td>\n",
       "      <td>671</td>\n",
       "      <td>36278</td>\n",
       "      <td>566</td>\n",
       "      <td>11478</td>\n",
       "      <td>5010</td>\n",
       "      <td>5114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         headline        date  \\\n",
       "count                                       51125       51128   \n",
       "unique                                      49839         334   \n",
       "top     Coronavirus Briefing: What Happened Today  2020-11-03   \n",
       "freq                                          182         901   \n",
       "\n",
       "                                                  web_url doc_type  \\\n",
       "count                                               51128    51128   \n",
       "unique                                              51127        3   \n",
       "top     https://www.nytimes.com/2020/10/06/world/cuomo...  article   \n",
       "freq                                                    2    46933   \n",
       "\n",
       "        lead_paragraph material_type                 author section  \\\n",
       "count            50086         49878                  45225   51127   \n",
       "unique           43656            19                  10431      51   \n",
       "top     To the Editor:          News  By The New York Times    U.S.   \n",
       "freq               671         36278                    566   11478   \n",
       "\n",
       "       subsection keywords  \n",
       "count       21826    51128  \n",
       "unique         83    32827  \n",
       "top      Politics       []  \n",
       "freq         5010     5114  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d2f37-2479-4c1b-9581-6e4b4c10c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31d2d0-4d66-47d6-a487-5a7d244123d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/usr/local/bin/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2334e7f-f5a9-4e36-afd3-c1dfe77e6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body(url):\n",
    "    driver.get(url)\n",
    "    article_text = ''\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    paragraph = soup.find_all('p')\n",
    "    for i in paragraph:\n",
    "        a = i.get_text()\n",
    "        if a != 'Advertisement' and a != 'Supported by' and a != 'Send any friend a story' and a != 'As a subscriber, you have 10 gift articles to give each month. Anyone can read what you share.' and not a.startswith(\"By\"):\n",
    "            article_text += a \n",
    "            article_text += \" \"\n",
    "    time.sleep(8)\n",
    "    return article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f9833-c2ec-4c2b-bdc8-a0877df5b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/nyt_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e65e8-2879-469a-9fd9-47bea821fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE A NEW COLUMN IN THE DATAFRAME CALLED \"article_doby\" WHERE WE ARE GOING TO APPEND THE TEXT RETRIEVE FROM \n",
    "## THE URL. NOTE: web_url REFERS TO THE COLUMN IN THE DATASET CONTAINING THE URL OF THE ARTICLE TO PASS TO get_body.\n",
    "\n",
    "df['article_body'] = df.apply(lambda x: get_body(x.web_url), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b410d6f-c09e-46b6-8984-0614d5fd9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da58b5a-bd76-48fb-9e93-affe18eabfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"FILE_PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ec2dd-8a3b-4d6f-8280-8a74741d13b3",
   "metadata": {},
   "source": [
    "#### Fox Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4c38d109-b4df-407c-b034-28d71f6c85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "all_urls = []\n",
    "url = 'https://www.cnn.com'\n",
    "data = requests.get(url).text\n",
    "soup = BeautifulSoup(data, features=\"html.parser\")\n",
    "for a in soup.find_all('a', href=True):\n",
    "    if a['href'] and a['href'][0] == '/' and a['href'] != '#':\n",
    "        a['href'] = url + a['href']\n",
    "    all_urls.append(a['href'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0a42f229-4182-4888-847b-16fc36dd20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_is_article(url, year='2020'):\n",
    "    if url:\n",
    "        if 'cnn.com/{}/'.format(year) in url and '/gallery/' not in url:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "article_urls = [url for url in all_urls if url_is_article(url)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2dee94e5-f36a-422d-9625-560e0db0eda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(article_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fcf33822-6ce1-44bb-b02b-d561588c26f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 20200101...\n",
      "No snapshot found for 20200101\n",
      "Scraping 20200102...\n",
      "No snapshot found for 20200102\n",
      "Scraping 20200103...\n",
      "Scraping 20200104...\n",
      "No snapshot found for 20200104\n",
      "Scraping 20200105...\n",
      "No snapshot found for 20200105\n",
      "Scraping 20200106...\n",
      "No snapshot found for 20200106\n",
      "Scraping 20200107...\n",
      "Scraping 20200108...\n",
      "No snapshot found for 20200108\n",
      "Scraping 20200109...\n",
      "Scraping 20200110...\n",
      "\n",
      "✅ Collected 0 articles from January 2020\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def get_wayback_snapshot(base_url, date_str):\n",
    "    api_url = f\"https://archive.org/wayback/available?url={base_url}&timestamp={date_str}\"\n",
    "    response = requests.get(api_url)\n",
    "    data = response.json()\n",
    "    try:\n",
    "        snapshot = data['archived_snapshots']['closest']['url']\n",
    "        return snapshot\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def scrape_titles_from_snapshot(snapshot_url, base_url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    res = requests.get(snapshot_url, headers=headers)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    articles = []\n",
    "    # Fox News often uses <h2> or <h4> tags with links inside\n",
    "    for tag in soup.find_all(['h2', 'h4']):\n",
    "        a = tag.find('a')\n",
    "        if a and a.text.strip():\n",
    "            title = a.text.strip()\n",
    "            href = a.get('href')\n",
    "            if href and not href.startswith('http'):\n",
    "                href = urljoin(\"https://web.archive.org\", href)\n",
    "            articles.append((title, href))\n",
    "    return articles\n",
    "\n",
    "# Loop through all days in January 2020\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2020, 1, 10)\n",
    "\n",
    "base_url = \"https://www.foxnews.com\"\n",
    "data = []\n",
    "\n",
    "while start_date <= end_date:\n",
    "    date_str = start_date.strftime('%Y%m%d')\n",
    "    print(f\"Scraping {date_str}...\")\n",
    "    \n",
    "    snapshot_url = get_wayback_snapshot(base_url, date_str)\n",
    "    if snapshot_url:\n",
    "        try:\n",
    "            articles = scrape_titles_from_snapshot(snapshot_url, base_url)\n",
    "            for title, url in articles:\n",
    "                data.append({\n",
    "                    \"title\": title,\n",
    "                    \"date\": start_date.strftime('%Y-%m-%d')\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {date_str}: {e}\")\n",
    "    else:\n",
    "        print(f\"No snapshot found for {date_str}\")\n",
    "    \n",
    "    start_date += timedelta(days=1)\n",
    "    time.sleep(1)  # Be respectful to archive.org\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"\\n✅ Collected {len(df)} articles from January 2020\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4b32ff62-c6c2-44c5-bd29-a476d32d4148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "780a2b4c-cb24-41ba-9d39-cae7accdf2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       http://web.archive.org/web/20200102000431/http...\n",
       "1       http://web.archive.org/web/20200102000431/http...\n",
       "2       http://web.archive.org/web/20200102000431/http...\n",
       "3       http://web.archive.org/web/20200102000431/http...\n",
       "4       http://web.archive.org/web/20200102000431/http...\n",
       "                              ...                        \n",
       "1524    https://web.archive.org/web/20200110231303/htt...\n",
       "1525    https://web.archive.org/web/20200110231303/htt...\n",
       "1526    https://web.archive.org/web/20200110231303/htt...\n",
       "1527    https://web.archive.org/web/20200110231303/htt...\n",
       "1528    https://web.archive.org/web/20200110231303/htt...\n",
       "Name: url, Length: 1529, dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c594ae-2687-4801-9cc4-dbee5f365b84",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
