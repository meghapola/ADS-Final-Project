{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d30b10-773a-40ff-b6ec-e255c987cd35",
   "metadata": {},
   "source": [
    "## **Applied Data Science Final Project**\n",
    "\n",
    "##### Megha Polavarapu (mp4392), Xiaoying Wang (xw2993), Iris June Chang (ijc2119), Mengyan Li (ml4779)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cdeee0-bea1-4cc4-b69b-c9a181e066d6",
   "metadata": {},
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a4f6a7-a861-4547-bc62-39146a5988a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import dateutil\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f8e0f77-d270-4347-933a-3b56a984ca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from fastparquet) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from fastparquet) (1.26.4)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from fastparquet) (2024.6.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from fastparquet) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Downloading fastparquet-2024.11.0-cp312-cp312-macosx_11_0_arm64.whl (685 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m685.4/685.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cramjam-2.10.0-cp312-cp312-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cramjam, fastparquet\n",
      "Successfully installed cramjam-2.10.0 fastparquet-2024.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5bfa6a-4f75-4621-b61d-ba84acb49437",
   "metadata": {},
   "outputs": [],
   "source": [
    "## might need to unzip/rezip to upload to github bc of file size limitations \n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78acf29b-000e-476a-9370-b6b1df9465c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad40455-b294-46d0-a6b4-4656462ff512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a343ce6d-78b0-4696-8ab7-965fcccadea6",
   "metadata": {},
   "source": [
    "#### **Presidential Election Data 2020 by Precinct**\n",
    "Data set link: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/NT66Z3\n",
    "Citation: MIT Election Data and Science Lab, 2022, \"Precinct-Level Returns 2020 by Individual State\", https://doi.org/10.7910/DVN/NT66Z3, Harvard Dataverse, V6, UNF:6:aViWPnsxmDD+s1GuFrrdpA== [fileUNF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "608b691b-e3c1-4c5d-8f40-ad1dee3c05af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-la-precinct-general.csv', '2020-tx-precinct-general.csv', '2020-nd-precinct-general.csv', '2020-ky-precinct-general.csv', '2020-mi-precinct-general.csv', '2020-ks-precinct-general.csv', '2020-wa-precinct-general.csv', '2020-or-precinct-general.csv', '2020-ms-precinct-general.csv', '2020-de-precinct-general.csv', '2020-ri-precinct-general.csv', '2020-oh-precinct-general.csv', '2020-ar-precinct-general.csv', '2020-al-precinct-general.csv', '2020-ut-precinct-general.csv', '2020-nj-precinct-general.csv', '2020-sd-precinct-general.csv', '2020-il-precinct-general.csv', '2020-ne-precinct-general.csv', '2020-nc-precinct-general-sorted.csv', '2020-ct-precinct-general.csv', '2020-nc-precinct-general.csv', '2020-mn-precinct-general.csv', '2020-fl-precinct-general.csv', '2020-wi-precinct-general.csv', '2020-ma-precinct-general.csv', '2020-tn-precinct-general.csv', '2020-md-precinct-general.csv', '2020-va-precinct-general.csv', '2020-ok-precinct-general.csv', '2020-ga-precinct-general.csv', '2020-co-precinct-general.csv', '2020-dc-precinct-general.csv', '2020-ia-precinct-general.csv', '2020-nh-precinct-general.csv', '2020-ak-precinct-general.csv', '2020-sc-precinct-general.csv', '2020-me-precinct-general.csv', '2020-nm-precinct-general.csv', '2020-id-precinct-general.csv', '2020-vt-precinct-general.csv', '2020-in-precinct-general.csv', '2020-pa-precinct-general.csv', '2020-mo-precinct-general.csv', '2020-az-precinct-general.csv', '2020-ny-precinct-general.csv', '2020-wv-precinct-general.csv', '2020-hi-precinct-general.csv', '2020-mt-precinct-general.csv', '2020-ca-precinct-general.csv', '2020-nv-precinct-general.csv', '2020-wy-precinct-general.csv']\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "PATH_NAME = 'data/raw/precinct_election_data/'\n",
    "\n",
    "filenames = next(os.walk(PATH_NAME), (None, None, []))[2]\n",
    "filenames.remove('README.md')\n",
    "filenames.remove('2020-precincts-codebook.md')\n",
    "filenames.remove('.Rhistory')\n",
    "print(filenames)\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a609508a-6ef5-47e8-a281-f504b7fff65d",
   "metadata": {},
   "source": [
    "Based on there being 52 file names, we can tell there is a duplicate (North Carolina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "16f14d8e-a2f8-44b3-93a4-64988099ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/2650330106.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nc = pd.read_csv(file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/2650330106.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nc_sorted = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696804\n",
      "1529852\n"
     ]
    }
   ],
   "source": [
    "file = 'data/raw/precinct_election_data/2020-nc-precinct-general.csv'\n",
    "nc = pd.read_csv(file)\n",
    "file = 'data/rawprecinct_election_data/2020-nc-precinct-general-sorted.csv'\n",
    "nc_sorted = pd.read_csv(file)\n",
    "\n",
    "print(nc.shape[0])\n",
    "print(nc_sorted.shape[0])\n",
    "\n",
    "filenames.remove('2020-nc-precinct-general-sorted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369a5361-b12f-49fa-b96f-338363bf72eb",
   "metadata": {},
   "source": [
    "We choose to keep the sorted data because it has more data. Based on the readMe for this dataset, contains additional information about the ballots used which could be used and therefore, this dataset will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0e8502fe-bc7f-4d5b-908f-e33f4138c321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-la-precinct-general.csv\n",
      "Loading file  2020-tx-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (2,3,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-nd-precinct-general.csv\n",
      "Loading file  2020-ky-precinct-general.csv\n",
      "Loading file  2020-mi-precinct-general.csv\n",
      "Loading file  2020-ks-precinct-general.csv\n",
      "Loading file  2020-wa-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-or-precinct-general.csv\n",
      "Loading file  2020-ms-precinct-general.csv\n",
      "Loading file  2020-de-precinct-general.csv\n",
      "Loading file  2020-ri-precinct-general.csv\n",
      "Loading file  2020-oh-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-ar-precinct-general.csv\n",
      "Loading file  2020-al-precinct-general.csv\n",
      "Loading file  2020-ut-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-nj-precinct-general.csv\n",
      "Loading file  2020-sd-precinct-general.csv\n",
      "Loading file  2020-il-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (0,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-ne-precinct-general.csv\n",
      "Loading file  2020-ct-precinct-general.csv\n",
      "Loading file  2020-nc-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-mn-precinct-general.csv\n",
      "Loading file  2020-fl-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (2,3,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-wi-precinct-general.csv\n",
      "Loading file  2020-ma-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-tn-precinct-general.csv\n",
      "Loading file  2020-md-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-va-precinct-general.csv\n",
      "Loading file  2020-ok-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-ga-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-co-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-dc-precinct-general.csv\n",
      "Loading file  2020-ia-precinct-general.csv\n",
      "Loading file  2020-nh-precinct-general.csv\n",
      "Loading file  2020-ak-precinct-general.csv\n",
      "Loading file  2020-sc-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n",
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-me-precinct-general.csv\n",
      "Loading file  2020-nm-precinct-general.csv\n",
      "Loading file  2020-id-precinct-general.csv\n",
      "Loading file  2020-vt-precinct-general.csv\n",
      "Loading file  2020-in-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-pa-precinct-general.csv\n",
      "Loading file  2020-mo-precinct-general.csv\n",
      "Loading file  2020-az-precinct-general.csv\n",
      "Loading file  2020-ny-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  2020-wv-precinct-general.csv\n",
      "Loading file  2020-hi-precinct-general.csv\n",
      "Loading file  2020-mt-precinct-general.csv\n",
      "Loading file  2020-ca-precinct-general.csv\n",
      "Loading file  2020-nv-precinct-general.csv\n",
      "Loading file  2020-wy-precinct-general.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/wprmb_s52rs0t4r2gfzh2df00000gn/T/ipykernel_48888/3231263860.py:5: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(PATH_NAME + file)\n"
     ]
    }
   ],
   "source": [
    "# file = 'data/raw/precinct_election_data/2020-wv-precinct-general.csv'\n",
    "combined = pd.DataFrame()\n",
    "for file in filenames:\n",
    "    print('Loading file ', file)\n",
    "    d = pd.read_csv(PATH_NAME + file)\n",
    "            \n",
    "    # standardizing formatting in precinct column \n",
    "    d['precinct'] = d['precinct'].replace('PRECINCT ', '')\n",
    "    d['votes'] = d['votes'].astype(int)\n",
    "    \n",
    "    # only keeping presidential election data \n",
    "    df = d.groupby(['candidate','office', 'party_detailed',\t'party_simplified',\t'state','state_po'], as_index=False)['votes'].sum()\n",
    "    \n",
    "    # re adding relevant data \n",
    "    # df = df.drop(columns = ['precinct', 'mode', \n",
    "    #        'county_name', 'county_fips', 'jurisdiction_name',\n",
    "    #        'jurisdiction_fips', 'district', 'magnitude', 'dataverse',\n",
    "    #        'year', 'stage', 'special', 'writein', 'state_fips', 'state_cen', 'state_ic', 'date', 'readme_check'])\n",
    "    # df = df.merge(d, left_on='candidate', right_on='candidate', how='left')\n",
    "    # df = df.drop_duplicates().reset_index()\n",
    "    # df= df.drop(columns = ['index'])\n",
    "    \n",
    "    combined = pd.concat([combined,df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f34e947d-3a17-4edf-9258-91e96072afb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate           object\n",
       "office              object\n",
       "party_detailed      object\n",
       "party_simplified    object\n",
       "state               object\n",
       "state_po            object\n",
       "votes                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "6223214e-1d86-4704-939a-957f3266256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['LOUISIANA', 'TEXAS', 'NORTH DAKOTA', 'KENTUCKY', 'MICHIGAN',\n",
      "       'KANSAS', 'WASHINGTON', 'OREGON', 'MISSISSIPPI', 'DELAWARE',\n",
      "       'RHODE ISLAND', 'OHIO', 'ARKANSAS', 'ALABAMA', 'UTAH',\n",
      "       'NEW JERSEY', 'SOUTH DAKOTA', 'ILLINOIS', 'NEBRASKA',\n",
      "       'CONNECTICUT', 'NORTH CAROLINA', 'MINNESOTA', 'FLORIDA',\n",
      "       'WISCONSIN', 'MASSACHUSETTS', 'TENNESSEE', 'MARYLAND', 'VIRGINIA',\n",
      "       'OKLAHOMA', 'GEORGIA', 'COLORADO', 'DISTRICT OF COLUMBIA', 'IOWA',\n",
      "       'NEW HAMPSHIRE', 'ALASKA', 'SOUTH CAROLINA', 'MAINE', 'NEW MEXICO',\n",
      "       'IDAHO', 'VERMONT', 'INDIANA', 'PENNSYLVANIA', 'MISSOURI',\n",
      "       'ARIZONA', 'NEW YORK', 'WEST VIRGINIA', 'HAWAII', 'MONTANA',\n",
      "       'CALIFORNIA', 'NEVADA', 'WYOMING'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "combined.head()\n",
    "print([combined[col_name].unique() for col_name in combined.columns if col_name == 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "ae867b21-f341-4f59-b917-33d05aca0d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('data/2020_election_vote_counts.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "d6ef8561-7c36-4626-805e-2779614a7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting who won each state \n",
    "top_candidates = combined.loc[combined.groupby(['office', 'state'])['votes'].idxmax()].reset_index(drop=True)\n",
    "top_candidates = top_candidates.sort_values('state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "96d8b09c-b0bc-4dfd-bd5d-1eb505606b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>office</th>\n",
       "      <th>party_detailed</th>\n",
       "      <th>party_simplified</th>\n",
       "      <th>state</th>\n",
       "      <th>state_po</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22835</th>\n",
       "      <td>MARY WINDOM</td>\n",
       "      <td>COURT OF CRIMINAL APPEALS JUDGE</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>1541862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22537</th>\n",
       "      <td>JOELETTA MARTIN BARRENTINE</td>\n",
       "      <td>CIRCUIT COURT JUDGE</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>26536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19299</th>\n",
       "      <td>TONYA SMITH CHESTNUT</td>\n",
       "      <td>STATE BOARD OF EDUCATION</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>161192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10242</th>\n",
       "      <td>TERRI A SEWELL</td>\n",
       "      <td>US HOUSE</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>225742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22697</th>\n",
       "      <td>DONALD J TRUMP</td>\n",
       "      <td>US PRESIDENT</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>1441170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>DONALD J TRUMP</td>\n",
       "      <td>US PRESIDENT</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>WY</td>\n",
       "      <td>193559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>BILL HENDERSON</td>\n",
       "      <td>STATE HOUSE</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>WY</td>\n",
       "      <td>2497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18228</th>\n",
       "      <td>LEVI J SHINKLE</td>\n",
       "      <td>STATE HOUSE</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>WY</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15575</th>\n",
       "      <td>OCEAN ANDREW</td>\n",
       "      <td>STATE HOUSE</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>WY</td>\n",
       "      <td>3409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>PETER H FROELICHER - NO</td>\n",
       "      <td>DISTRICT COURT JUDGE</td>\n",
       "      <td>NONPARTISAN</td>\n",
       "      <td>NONPARTISAN</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>WY</td>\n",
       "      <td>9222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24461 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        candidate                           office  \\\n",
       "22835                 MARY WINDOM  COURT OF CRIMINAL APPEALS JUDGE   \n",
       "22537  JOELETTA MARTIN BARRENTINE              CIRCUIT COURT JUDGE   \n",
       "19299        TONYA SMITH CHESTNUT         STATE BOARD OF EDUCATION   \n",
       "10242              TERRI A SEWELL                         US HOUSE   \n",
       "22697              DONALD J TRUMP                     US PRESIDENT   \n",
       "...                           ...                              ...   \n",
       "8275               DONALD J TRUMP                     US PRESIDENT   \n",
       "7836               BILL HENDERSON                      STATE HOUSE   \n",
       "18228              LEVI J SHINKLE                      STATE HOUSE   \n",
       "15575                OCEAN ANDREW                      STATE HOUSE   \n",
       "3705      PETER H FROELICHER - NO             DISTRICT COURT JUDGE   \n",
       "\n",
       "      party_detailed party_simplified    state state_po    votes  \n",
       "22835     REPUBLICAN       REPUBLICAN  ALABAMA       AL  1541862  \n",
       "22537     REPUBLICAN       REPUBLICAN  ALABAMA       AL    26536  \n",
       "19299       DEMOCRAT         DEMOCRAT  ALABAMA       AL   161192  \n",
       "10242       DEMOCRAT         DEMOCRAT  ALABAMA       AL   225742  \n",
       "22697     REPUBLICAN       REPUBLICAN  ALABAMA       AL  1441170  \n",
       "...              ...              ...      ...      ...      ...  \n",
       "8275      REPUBLICAN       REPUBLICAN  WYOMING       WY   193559  \n",
       "7836      REPUBLICAN       REPUBLICAN  WYOMING       WY     2497  \n",
       "18228       DEMOCRAT         DEMOCRAT  WYOMING       WY      816  \n",
       "15575     REPUBLICAN       REPUBLICAN  WYOMING       WY     3409  \n",
       "3705     NONPARTISAN      NONPARTISAN  WYOMING       WY     9222  \n",
       "\n",
       "[24461 rows x 7 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ac0269c0-c433-408d-b076-7a05d90cf2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_candidates.to_csv('data/2020_election_vote_results.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3586a4-d30d-43e5-b30e-60c5be94d25c",
   "metadata": {},
   "source": [
    "#### **NYT Web Scraping**\n",
    "##### References:    \n",
    "- https://github.com/susannapaoli/web-scraper-nyt/tree/main    \n",
    "- https://developer.nytimes.com/get-started    \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d228edd9-1ada-40ef-a8ce-5f9c7793689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'bgsBWGVUUDgyvMaTcXZZy4yd9Ogsehqh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "7d304711-de85-4b58-88d4-c70bdd1aaf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response):\n",
    "    data = {'headline': [],  \n",
    "        'date': [], \n",
    "        'web_url': [],\n",
    "        'doc_type': [],\n",
    "        'lead_paragraph': [],\n",
    "        'material_type': [],\n",
    "        'author': [],\n",
    "        'section': [],\n",
    "        'subsection': [],\n",
    "        'keywords': []}\n",
    "\n",
    "    articles = response['response']['docs'] \n",
    "    for article in articles: \n",
    "        date = dateutil.parser.parse(article['pub_date']).date()\n",
    "        # if date != datetime.date(2020, 1, 1):\n",
    "        #     continue\n",
    "        if type(article['headline']) == dict and 'main' in article['headline'].keys():\n",
    "            data['date'].append(date)\n",
    "            data['headline'].append(article['headline']['main']) \n",
    "            if 'section_name' in article:\n",
    "                data['section'].append(article['section_name'])\n",
    "            else:\n",
    "                data['section'].append(None)\n",
    "            if 'lead_paragraph' in article:\n",
    "                data['lead_paragraph'].append(article['lead_paragraph'])\n",
    "            else:\n",
    "                data['lead_paragraph'].append(None)\n",
    "            if 'web_url' in article:\n",
    "                data['web_url'].append(article['web_url'])\n",
    "            else:\n",
    "                data['web_url'].append(None)\n",
    "            if 'subsection_name' in article:\n",
    "                data['subsection'].append(article['subsection_name'])\n",
    "            else:\n",
    "                data['subsection'].append(None)\n",
    "            if 'byline' in article:\n",
    "                data['author'].append(article['byline']['original'])\n",
    "            else:\n",
    "                data['author'].append(None)\n",
    "            data['doc_type'].append(article['document_type'])\n",
    "            if 'type_of_material' in article: \n",
    "                data['material_type'].append(article['type_of_material'])\n",
    "            else:\n",
    "                data['material_type'].append(None)\n",
    "            keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
    "            data['keywords'].append(keywords)\n",
    "    return pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "316f2e98-6bf6-4375-82a5-277735964e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ['2020', '1']\n",
      "Working on ['2020', '2']\n",
      "Working on ['2020', '3']\n",
      "Working on ['2020', '4']\n",
      "Working on ['2020', '5']\n"
     ]
    }
   ],
   "source": [
    "# Get data from January 2020 to May 2020 \n",
    "for i in range(1,6): \n",
    "    date = ['2020', str(i)]\n",
    "    print('Working on', date)\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
    "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + API_KEY\n",
    "    response = requests.get(url, verify=False).json()\n",
    "    time.sleep(6) \n",
    "    \n",
    "    df = parse_response(response)\n",
    "    csv_path = 'data/raw/nyt_headlines/' + date[0] + '-' + date[1] + '.csv'\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0173ab5b-66ad-4374-9481-2a5af595fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ['2020', '6']\n",
      "Working on ['2020', '7']\n",
      "Working on ['2020', '8']\n",
      "Working on ['2020', '9']\n",
      "Working on ['2020', '10']\n",
      "Working on ['2020', '11']\n"
     ]
    }
   ],
   "source": [
    "# Get data from June 2020 to November 2020 \n",
    "for i in range(6,12): \n",
    "    date = ['2020', str(i)]\n",
    "    print('Working on', date)\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
    "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + API_KEY\n",
    "    response = requests.get(url, verify=False).json()\n",
    "    time.sleep(6) \n",
    "    \n",
    "    df = parse_response(response)\n",
    "    csv_path = 'data/raw/nyt_headlines/' + date[0] + '-' + date[1] + '.csv'\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "db495b64-b733-4a28-b699-d0f9343c024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['data/raw/nyt_headlines/2020-' + str(i) + '.csv' for i in range(1,12)]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for f in files:\n",
    "    d = pd.read_csv(f)\n",
    "    df = pd.concat([df,d], axis=0)\n",
    "\n",
    "#export to csv\n",
    "df.to_csv(\"data/nyt_data.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "aaa52386-446c-42c7-96ed-105403112fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = pd.read_csv('data/nyt_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "ae41eab4-9471-432d-be2f-693a0fe99e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>web_url</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>material_type</th>\n",
       "      <th>author</th>\n",
       "      <th>section</th>\n",
       "      <th>subsection</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51125</td>\n",
       "      <td>51128</td>\n",
       "      <td>51128</td>\n",
       "      <td>51128</td>\n",
       "      <td>50086</td>\n",
       "      <td>49878</td>\n",
       "      <td>45225</td>\n",
       "      <td>51127</td>\n",
       "      <td>21826</td>\n",
       "      <td>51128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49839</td>\n",
       "      <td>334</td>\n",
       "      <td>51127</td>\n",
       "      <td>3</td>\n",
       "      <td>43656</td>\n",
       "      <td>19</td>\n",
       "      <td>10431</td>\n",
       "      <td>51</td>\n",
       "      <td>83</td>\n",
       "      <td>32827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Coronavirus Briefing: What Happened Today</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>https://www.nytimes.com/2020/10/06/world/cuomo...</td>\n",
       "      <td>article</td>\n",
       "      <td>To the Editor:</td>\n",
       "      <td>News</td>\n",
       "      <td>By The New York Times</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>182</td>\n",
       "      <td>901</td>\n",
       "      <td>2</td>\n",
       "      <td>46933</td>\n",
       "      <td>671</td>\n",
       "      <td>36278</td>\n",
       "      <td>566</td>\n",
       "      <td>11478</td>\n",
       "      <td>5010</td>\n",
       "      <td>5114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         headline        date  \\\n",
       "count                                       51125       51128   \n",
       "unique                                      49839         334   \n",
       "top     Coronavirus Briefing: What Happened Today  2020-11-03   \n",
       "freq                                          182         901   \n",
       "\n",
       "                                                  web_url doc_type  \\\n",
       "count                                               51128    51128   \n",
       "unique                                              51127        3   \n",
       "top     https://www.nytimes.com/2020/10/06/world/cuomo...  article   \n",
       "freq                                                    2    46933   \n",
       "\n",
       "        lead_paragraph material_type                 author section  \\\n",
       "count            50086         49878                  45225   51127   \n",
       "unique           43656            19                  10431      51   \n",
       "top     To the Editor:          News  By The New York Times    U.S.   \n",
       "freq               671         36278                    566   11478   \n",
       "\n",
       "       subsection keywords  \n",
       "count       21826    51128  \n",
       "unique         83    32827  \n",
       "top      Politics       []  \n",
       "freq         5010     5114  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d2f37-2479-4c1b-9581-6e4b4c10c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31d2d0-4d66-47d6-a487-5a7d244123d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/usr/local/bin/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2334e7f-f5a9-4e36-afd3-c1dfe77e6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body(url):\n",
    "    driver.get(url)\n",
    "    article_text = ''\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    paragraph = soup.find_all('p')\n",
    "    for i in paragraph:\n",
    "        a = i.get_text()\n",
    "        if a != 'Advertisement' and a != 'Supported by' and a != 'Send any friend a story' and a != 'As a subscriber, you have 10 gift articles to give each month. Anyone can read what you share.' and not a.startswith(\"By\"):\n",
    "            article_text += a \n",
    "            article_text += \" \"\n",
    "    time.sleep(8)\n",
    "    return article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f9833-c2ec-4c2b-bdc8-a0877df5b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/nyt_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e65e8-2879-469a-9fd9-47bea821fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE A NEW COLUMN IN THE DATAFRAME CALLED \"article_doby\" WHERE WE ARE GOING TO APPEND THE TEXT RETRIEVE FROM \n",
    "## THE URL. NOTE: web_url REFERS TO THE COLUMN IN THE DATASET CONTAINING THE URL OF THE ARTICLE TO PASS TO get_body.\n",
    "\n",
    "df['article_body'] = df.apply(lambda x: get_body(x.web_url), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b410d6f-c09e-46b6-8984-0614d5fd9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da58b5a-bd76-48fb-9e93-affe18eabfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"FILE_PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ec2dd-8a3b-4d6f-8280-8a74741d13b3",
   "metadata": {},
   "source": [
    "#### Fox Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4c38d109-b4df-407c-b034-28d71f6c85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "all_urls = []\n",
    "url = 'https://www.cnn.com'\n",
    "data = requests.get(url).text\n",
    "soup = BeautifulSoup(data, features=\"html.parser\")\n",
    "for a in soup.find_all('a', href=True):\n",
    "    if a['href'] and a['href'][0] == '/' and a['href'] != '#':\n",
    "        a['href'] = url + a['href']\n",
    "    all_urls.append(a['href'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0a42f229-4182-4888-847b-16fc36dd20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_is_article(url, year='2020'):\n",
    "    if url:\n",
    "        if 'cnn.com/{}/'.format(year) in url and '/gallery/' not in url:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "article_urls = [url for url in all_urls if url_is_article(url)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2dee94e5-f36a-422d-9625-560e0db0eda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(article_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fcf33822-6ce1-44bb-b02b-d561588c26f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 20200101...\n",
      "No snapshot found for 20200101\n",
      "Scraping 20200102...\n",
      "No snapshot found for 20200102\n",
      "Scraping 20200103...\n",
      "Scraping 20200104...\n",
      "No snapshot found for 20200104\n",
      "Scraping 20200105...\n",
      "No snapshot found for 20200105\n",
      "Scraping 20200106...\n",
      "No snapshot found for 20200106\n",
      "Scraping 20200107...\n",
      "Scraping 20200108...\n",
      "No snapshot found for 20200108\n",
      "Scraping 20200109...\n",
      "Scraping 20200110...\n",
      "\n",
      "✅ Collected 0 articles from January 2020\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def get_wayback_snapshot(base_url, date_str):\n",
    "    api_url = f\"https://archive.org/wayback/available?url={base_url}&timestamp={date_str}\"\n",
    "    response = requests.get(api_url)\n",
    "    data = response.json()\n",
    "    try:\n",
    "        snapshot = data['archived_snapshots']['closest']['url']\n",
    "        return snapshot\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def scrape_titles_from_snapshot(snapshot_url, base_url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    res = requests.get(snapshot_url, headers=headers)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    articles = []\n",
    "    # Fox News often uses <h2> or <h4> tags with links inside\n",
    "    for tag in soup.find_all(['h2', 'h4']):\n",
    "        a = tag.find('a')\n",
    "        if a and a.text.strip():\n",
    "            title = a.text.strip()\n",
    "            href = a.get('href')\n",
    "            if href and not href.startswith('http'):\n",
    "                href = urljoin(\"https://web.archive.org\", href)\n",
    "            articles.append((title, href))\n",
    "    return articles\n",
    "\n",
    "# Loop through all days in January 2020\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2020, 1, 10)\n",
    "\n",
    "base_url = \"https://www.foxnews.com\"\n",
    "data = []\n",
    "\n",
    "while start_date <= end_date:\n",
    "    date_str = start_date.strftime('%Y%m%d')\n",
    "    print(f\"Scraping {date_str}...\")\n",
    "    \n",
    "    snapshot_url = get_wayback_snapshot(base_url, date_str)\n",
    "    if snapshot_url:\n",
    "        try:\n",
    "            articles = scrape_titles_from_snapshot(snapshot_url, base_url)\n",
    "            for title, url in articles:\n",
    "                data.append({\n",
    "                    \"title\": title,\n",
    "                    \"date\": start_date.strftime('%Y-%m-%d')\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {date_str}: {e}\")\n",
    "    else:\n",
    "        print(f\"No snapshot found for {date_str}\")\n",
    "    \n",
    "    start_date += timedelta(days=1)\n",
    "    time.sleep(1)  # Be respectful to archive.org\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"\\n✅ Collected {len(df)} articles from January 2020\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4b32ff62-c6c2-44c5-bd29-a476d32d4148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "780a2b4c-cb24-41ba-9d39-cae7accdf2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       http://web.archive.org/web/20200102000431/http...\n",
       "1       http://web.archive.org/web/20200102000431/http...\n",
       "2       http://web.archive.org/web/20200102000431/http...\n",
       "3       http://web.archive.org/web/20200102000431/http...\n",
       "4       http://web.archive.org/web/20200102000431/http...\n",
       "                              ...                        \n",
       "1524    https://web.archive.org/web/20200110231303/htt...\n",
       "1525    https://web.archive.org/web/20200110231303/htt...\n",
       "1526    https://web.archive.org/web/20200110231303/htt...\n",
       "1527    https://web.archive.org/web/20200110231303/htt...\n",
       "1528    https://web.archive.org/web/20200110231303/htt...\n",
       "Name: url, Length: 1529, dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c594ae-2687-4801-9cc4-dbee5f365b84",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
